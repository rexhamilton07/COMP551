{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmgnvd_z-4sV"
      },
      "source": [
        "#Task 1: Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaie63LOArql"
      },
      "source": [
        "Imports & Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUv346RzBg8M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') #will only run once, ignore remount error after"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CZORlAaTXFaF"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Conv2D,MaxPool2D,Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.preprocessing import LabelBinarizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMUdGa1lAqh3"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IhmQ_P0Awv3"
      },
      "outputs": [],
      "source": [
        "for dirname, _, filenames in os.walk('/content/drive/MyDrive/sign-language-mnist'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "train_df=pd.read_csv('/content/drive/MyDrive/sign-language-mnist/sign_mnist_train/sign_mnist_train.csv')\n",
        "test_df=pd.read_csv('/content/drive/MyDrive/sign-language-mnist/sign_mnist_test/sign_mnist_test.csv')\n",
        "train_df.info()\n",
        "test_df.info()\n",
        "#train_df.head(10) #run this to check data was properly imported"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktECCRA2D80u"
      },
      "outputs": [],
      "source": [
        "train_label=train_df['label']\n",
        "trainset=train_df.drop(['label'],axis=1)\n",
        "X_train = trainset.values\n",
        "X_train_std = X_train - np.mean(X_train)\n",
        "X_train = X_train_std / np.std(X_train_std, axis = 0)\n",
        "test_label=test_df['label']\n",
        "X_test=test_df.drop(['label'],axis=1)\n",
        "X_test_std = X_test - np.mean(X_test)\n",
        "X_test = X_test_std / np.std(X_test_std, axis = 0)\n",
        "lb=LabelBinarizer()\n",
        "y_train=lb.fit_transform(train_label)\n",
        "y_test=lb.fit_transform(test_label)\n",
        "X_test= X_test.values.reshape(-1,28,28,1)\n",
        "X_train = X_train.reshape(-1,28,28,1)\n",
        "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1JwNw72CxAe"
      },
      "source": [
        "#Task 2: MLP Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CMvDRjaCzmh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from IPython.core.debugger import set_trace\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "\n",
        "def softmax(a):\n",
        "    exp_a = np.exp(a - np.max(a, axis=1, keepdims=True))\n",
        "    return exp_a / np.sum(exp_a, axis=1, keepdims=True)\n",
        "\n",
        "def relu(a):\n",
        "    return np.maximum(0, a)\n",
        "\n",
        "def relu_derivative(a):\n",
        "    return np.where(a <= 0, 0, 1)\n",
        "\n",
        "def sigmoid(a):\n",
        "    return 1 / (1 + np.exp(-a))\n",
        "\n",
        "def sigmoid_derivative(a):\n",
        "    return sigmoid(a) * (1 - sigmoid(a))\n",
        "\n",
        "def leaky_relu(a):\n",
        "    return np.where(a > 0, a, a * 0.01)\n",
        "\n",
        "def leaky_relu_derivative(a):\n",
        "    return np.where(a > 0, 1, 0.01)\n",
        "\n",
        "class MLP:\n",
        "    def __init__(self, input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units, l2_lambda=0.01):\n",
        "        self.activation_function = activation_function\n",
        "        self.activation_derivative = activation_derivative\n",
        "        self.hidden_layers = hidden_layers\n",
        "        self.layer_units = [input_units] + layer_units + [output_units]\n",
        "        self.weights = [np.random.randn(self.layer_units[i], self.layer_units[i+1]) * np.sqrt(2. / self.layer_units[i]) for i in range(len(self.layer_units) - 1)]\n",
        "        self.biases = [np.zeros((1, self.layer_units[i+1])) for i in range(len(self.layer_units) - 1)]\n",
        "        self.l2_lambda = l2_lambda\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "          a = X\n",
        "          activations = [X]\n",
        "          zs = []\n",
        "          for i, (w, b) in enumerate(zip(self.weights, self.biases)):\n",
        "              z = np.dot(a, w) + b\n",
        "              zs.append(z)\n",
        "              if i == len(self.weights) - 1:\n",
        "                  a = softmax(z)\n",
        "              else:\n",
        "                  a = activation_function(z)\n",
        "              activations.append(a)\n",
        "          return activations, zs\n",
        "\n",
        "    def backprop(self, X, y):\n",
        "        m = X.shape[0]\n",
        "        activations, zs = self.forward_pass(X)\n",
        "        delta = activations[-1] - y\n",
        "        dWs = [(np.dot(activations[-2].T, delta) + (self.l2_lambda * self.weights[-1])) / m]\n",
        "        dbs = [np.sum(delta, axis=0, keepdims=True) / m]\n",
        "        for l in range(2, self.hidden_layers + 2):\n",
        "            delta = np.dot(delta, self.weights[-l+1].T) * self.activation_derivative(zs[-l])\n",
        "            dW = (np.dot(activations[-l-1].T, delta) + (self.l2_lambda * self.weights[-l])) / m\n",
        "            db = np.sum(delta, axis=0, keepdims=True) / m\n",
        "            dWs.insert(0, dW)\n",
        "            dbs.insert(0, db)\n",
        "        return dWs, dbs\n",
        "\n",
        "    def update_params(self, dWs, dbs, lr):\n",
        "        self.weights = [w-lr*dw for w, dw in zip(self.weights, dWs)]\n",
        "        self.biases = [b-lr*db for b, db in zip(self.biases, dbs)]\n",
        "\n",
        "    def compute_loss(self, output, y):\n",
        "        m = y.shape[0]\n",
        "        output_clipped = np.clip(output, 1e-7, 1 - 1e-7)\n",
        "        log_probs = -np.log(output_clipped[range(m), y.argmax(axis=1)])\n",
        "        data_loss = np.sum(log_probs) / m\n",
        "        l2_penalty = sum([np.sum(w**2) for w in self.weights]) * (self.l2_lambda / (2*m))\n",
        "        return data_loss + l2_penalty\n",
        "\n",
        "    def compute_accuracy(self, output, y):\n",
        "        predictions = np.argmax(output, axis=1)\n",
        "        accuracy = np.mean(predictions == np.argmax(y, axis=1))\n",
        "        return accuracy\n",
        "\n",
        "    def fit(self, X, y, epochs, lr):\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            dWs, dbs = self.backprop(X, y)\n",
        "            self.update_params(dWs, dbs, lr)\n",
        "            if epoch % 10 == 0:\n",
        "                output = self.forward_pass(X)[0][-1]\n",
        "                loss = self.compute_loss(output, y)\n",
        "                accuracy = self.compute_accuracy(output, y)\n",
        "                print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy}')\n",
        "\n",
        "    def fit_plot(self, X, y, epochs, lr):\n",
        "      for epoch in tqdm(range(epochs)):\n",
        "          dWs, dbs = self.backprop(X, y)\n",
        "          self.update_params(dWs, dbs, lr)\n",
        "          if epoch % 10 == 0:\n",
        "              output = self.forward_pass(X)[0][-1]\n",
        "              loss = self.compute_loss(output, y)\n",
        "              accuracy = self.compute_accuracy(output, y)\n",
        "              print(f'Epoch {epoch}, Loss: {loss}, Accuracy: {accuracy}')\n",
        "          if epoch == epochs-1:\n",
        "            return self.compute_accuracy(output, y)\n",
        "\n",
        "    def predict(self, X):\n",
        "        output = self.forward_pass(X)[0][-1]\n",
        "        return np.argmax(output, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc8sdBjNIpMB"
      },
      "source": [
        "#Task 3.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRA4QBivgS8z"
      },
      "source": [
        "No Hidden Layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzj54E6kDaMU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 0\n",
        "layer_units = []\n",
        "activation_function = relu\n",
        "activation_derivative = relu_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk_S5fbzgWwN"
      },
      "source": [
        "One Hidden Layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eO-TXdhWgYZc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 1\n",
        "layer_units = [256]\n",
        "activation_function = relu\n",
        "activation_derivative = relu_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFFywZuigZnL"
      },
      "source": [
        "Two Hidden Layers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h6niFYQ9gbXV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 2\n",
        "layer_units = [256, 256]\n",
        "activation_function = relu\n",
        "activation_derivative = relu_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEJNRVNJqaSD"
      },
      "source": [
        "#Task 3.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFQp2G_uqc6e"
      },
      "source": [
        "Sigmoid Activation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQCK3bJUqeds"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 2\n",
        "layer_units = [256, 256]\n",
        "activation_function = sigmoid\n",
        "activation_derivative = sigmoid_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPu-trQYqe1k"
      },
      "source": [
        "Leaky Relu Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtEAjyrOqhH8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 2\n",
        "layer_units = [256, 256]\n",
        "activation_function = leaky_relu\n",
        "activation_derivative = leaky_relu_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKcaqr2TuKV4"
      },
      "source": [
        "#Task 3.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5X0szuEuotR"
      },
      "source": [
        "Lambda = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfxNHN99uUVU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BClmXUdOuMK1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 2\n",
        "layer_units = [256, 256]\n",
        "activation_function = relu\n",
        "activation_derivative = relu_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units, 0)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6NTH2KCuqKM"
      },
      "source": [
        "Lambda = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuxHpUnMutMZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "lb = LabelBinarizer()\n",
        "y_train = lb.fit_transform(train_label)\n",
        "y_test = lb.transform(test_label)\n",
        "input_units = X_train.shape[1] * X_train.shape[2]\n",
        "output_units = y_train.shape[1]\n",
        "hidden_layers = 2\n",
        "layer_units = [256, 256]\n",
        "activation_function = relu\n",
        "activation_derivative = relu_derivative\n",
        "\n",
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units, 1)\n",
        "epochs = 250\n",
        "learning_rate = 0.01\n",
        "mlp.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "accuracy = np.mean(y_pred == test_label.values)\n",
        "\n",
        "print(f'Test Accuracy: {accuracy}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrFa4rNgyJFF"
      },
      "source": [
        "#Task 3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CDEWvx45Tp2C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import regularizers, layers, models\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "\n",
        "num_classes = 24\n",
        "\n",
        "def build_model(hidden_units, dropout_rate=0.5, l2_rate=1e-4, optimizer='adam', lr=1e-3):\n",
        "    if optimizer == 'adam':\n",
        "        opt = Adam(learning_rate=lr)\n",
        "    elif optimizer == 'sgd':\n",
        "        opt = SGD(learning_rate=lr)\n",
        "    elif optimizer == 'rmsprop':\n",
        "        opt = RMSprop(learning_rate=lr)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported optimizer\")\n",
        "\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(hidden_units, activation='relu', kernel_regularizer=regularizers.l2(l2_rate)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(hidden_units, activation='relu', kernel_regularizer=regularizers.l2(l2_rate)),\n",
        "        layers.Dropout(dropout_rate),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "hidden_units_options = [ 32,64,128,256]\n",
        "optimizer_options = ['adam', 'sgd', 'rmsprop']\n",
        "\n",
        "best_accuracy = 0\n",
        "best_model_config = None\n",
        "config_accuracies = []\n",
        "\n",
        "for units in hidden_units_options:\n",
        "    for optimizer in optimizer_options:\n",
        "        model = build_model(units, optimizer=optimizer)\n",
        "        history = model.fit(\n",
        "            X_train, y_train,\n",
        "            epochs=25,\n",
        "            validation_split=0.1,\n",
        "        )\n",
        "        _, accuracy = model.evaluate(X_test, y_test)\n",
        "        print(f\"Model with {units} hidden units and {optimizer} optimizer has accuracy: {accuracy:.2f}\")\n",
        "\n",
        "        config_accuracies.append({\n",
        "            'units': units,\n",
        "            'optimizer': optimizer,\n",
        "            'train_acc': history.history['accuracy'],\n",
        "            'val_acc': history.history['val_accuracy'],\n",
        "            'test_acc': accuracy\n",
        "        })\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model_config = (units, optimizer)\n",
        "\n",
        "# After testing all configurations\n",
        "print(f\"Best performing model configuration: {best_model_config} with accuracy: {best_accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6se8zJ3yKrs"
      },
      "source": [
        "#Task 3.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLpDcdbbTQQk"
      },
      "outputs": [],
      "source": [
        "mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "train_accuracy = mlp.fit_plot(X_train.reshape(X_train.shape[0], -1), y_train, 1000, learning_rate)\n",
        "\n",
        "y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "test_accuracy = np.mean(y_pred == np.argmax(y_test, axis=1))\n",
        "\n",
        "print(\"Hidden Layers: \"+str(hidden_layers))\n",
        "print(\"Hidden Layer Units: \"+str(layer_units))\n",
        "print(\"Activation Function: ReLU\")\n",
        "print(\"Training Accuracy: \"+str(train_accuracy)+\" Testing Accuracy: \"+str(test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yjm01hUTyNAv"
      },
      "source": [
        "#Task 3.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FkeKxvHyPG2"
      },
      "source": [
        "MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZXtfgDTyOeQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "def train_and_evaluate_mlp(epochs):\n",
        "    mlp = MLP(input_units, output_units, activation_function, activation_derivative, hidden_layers, layer_units)\n",
        "    train_accuracy = mlp.fit_plot(X_train.reshape(X_train.shape[0], -1), y_train, epochs, learning_rate)\n",
        "\n",
        "    y_pred = mlp.predict(X_test.reshape(X_test.shape[0], -1))\n",
        "    test_accuracy = np.mean(y_pred == np.argmax(y_test, axis=1))\n",
        "\n",
        "    return train_accuracy, test_accuracy\n",
        "\n",
        "epoch_list = [10, 50, 100, 200, 500, 1000, 2000, 3000]\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "for epochs in epoch_list:\n",
        "    train_acc, test_acc = train_and_evaluate_mlp(epochs)\n",
        "    train_accuracies.append(train_acc)\n",
        "    test_accuracies.append(test_acc)\n",
        "\n",
        "# Plotting\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(epoch_list))\n",
        "\n",
        "plt.bar(index, train_accuracies, bar_width, label='Training Accuracy')\n",
        "plt.bar(index + bar_width, test_accuracies, bar_width, label='Testing Accuracy')\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training vs Testing Accuracy at Different Epochs')\n",
        "plt.xticks(index + bar_width / 2, epoch_list)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwxJUH5ETkTI"
      },
      "source": [
        "CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hUYMs8yTmsG"
      },
      "outputs": [],
      "source": [
        "# put cnn plot code here\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming config_accuracies contains the necessary data\n",
        "plt.figure(figsize=(14, 8))\n",
        "for config in config_accuracies:\n",
        "    label = f\"Units: {config['units']}, Optimizer: {config['optimizer']}\"\n",
        "    epochs = range(1, len(config['train_acc']) + 1)\n",
        "    plt.plot(epochs, config['train_acc'], label=label)\n",
        "plt.title('Training Accuracy with Differtent Optimization Algorithm')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "for config in config_accuracies:\n",
        "    label = f\"Units: {config['units']}, Optimizer: {config['optimizer']}\"\n",
        "    epochs = range(1, len(config['val_acc']) + 1)\n",
        "    plt.plot(epochs, config['val_acc'], '--', label=label)\n",
        "plt.title('Validation Accuracy with Differtent Optimization Algorithm')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}